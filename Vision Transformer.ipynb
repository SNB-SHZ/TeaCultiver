{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOiOmJq0uCYtQ1kM1osoAZ0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"RO9yAtg0c4vK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745987140456,"user_tz":-540,"elapsed":18694,"user":{"displayName":"REI SONOBE","userId":"07566553194322079362"}},"outputId":"1f245fa5-c26a-4d20-e000-e4c4056b422c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["# ‚úÖ „É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´„Å®„Ç§„É≥„Éù„Éº„Éà\n","!pip install -U scikit-learn einops\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","from einops import rearrange\n"],"metadata":{"id":"CoQEc0sXdBJ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745987158136,"user_tz":-540,"elapsed":16346,"user":{"displayName":"REI SONOBE","userId":"07566553194322079362"}},"outputId":"c28e14f8-87ec-4fe3-cc1a-fb2fe8ed1643"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"]}]},{"cell_type":"code","source":["from einops import rearrange\n","\n","class SpectralViT(nn.Module):\n","    def __init__(self, seq_len=91, patch_size=7, dim=128, depth=4, heads=4, mlp_dim=256):\n","        super().__init__()\n","        assert seq_len % patch_size == 0, \"patch size must divide seq_len\"\n","        self.patch_size = patch_size\n","        self.num_patches = seq_len // patch_size\n","        self.dim = dim\n","\n","        self.linear_proj = nn.Linear(patch_size, dim)\n","        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches, dim))\n","\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=mlp_dim, batch_first=True)\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n","\n","        self.mlp_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, 1)\n","        )\n","\n","    def forward(self, x):\n","        # x: (B, 1, 91) ‚Üí (B, 91)\n","        x = x.squeeze(1)  # remove channel dim\n","        x = rearrange(x, 'b (n p) -> b n p', p=self.patch_size)  # (B, num_patches, patch_size)\n","        x = self.linear_proj(x)  # (B, num_patches, dim)\n","        x = x + self.pos_embedding  # add positional embedding\n","        x = self.transformer(x)\n","        x = x.mean(dim=1)  # global average pooling\n","        return self.mlp_head(x)"],"metadata":{"id":"y-OMCoQJdDSG","executionInfo":{"status":"ok","timestamp":1745987160109,"user_tz":-540,"elapsed":13,"user":{"displayName":"REI SONOBE","userId":"07566553194322079362"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class SpectralDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = torch.tensor(X).unsqueeze(1)  # (N, 1, 91)\n","        self.y = torch.tensor(y).unsqueeze(1)\n","    def __len__(self):\n","        return len(self.X)\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n"],"metadata":{"id":"cRlbeIyHdHTd","executionInfo":{"status":"ok","timestamp":1745987162287,"user_tz":-540,"elapsed":18,"user":{"displayName":"REI SONOBE","userId":"07566553194322079362"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["base_path = \"/content/drive/MyDrive/Colab Notebooks/Tea\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","for i in range(1, 11):\n","    round_name = f\"Round{str(i).zfill(2)}\"\n","    data_path = os.path.join(base_path, round_name)\n","    print(f\"\\nüìÅ {round_name} Âá¶ÁêÜ‰∏≠...\")\n","\n","    # „Éá„Éº„ÇøË™≠„ÅøËæº„Åø\n","    train_df = pd.read_csv(os.path.join(data_path, \"training.csv\"))\n","    test_df = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n","    spectral_cols = train_df.columns[:-1]\n","    target_col = train_df.columns[-1]\n","\n","    X_train = train_df[spectral_cols].values.astype(np.float32)\n","    y_train = train_df[target_col].values.astype(np.float32)\n","    X_test = test_df[spectral_cols].values.astype(np.float32)\n","    y_test = test_df[target_col].values.astype(np.float32)\n","\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","\n","    train_ds = SpectralDataset(X_train, y_train)\n","    test_ds = SpectralDataset(X_test, y_test)\n","    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n","    test_loader = DataLoader(test_ds, batch_size=32)\n","\n","    # „É¢„Éá„É´ÊßãÁØâ\n","    model = SpectralViT(seq_len=91, patch_size=7).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    criterion = nn.MSELoss()\n","\n","    # Â≠¶Áøí\n","    for epoch in range(100):\n","        model.train()\n","        total_loss = 0\n","        for xb, yb in train_loader:\n","            xb, yb = xb.to(device), yb.to(device)\n","            pred = model(xb)\n","            loss = criterion(pred, yb)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        if (epoch + 1) % 10 == 0:\n","            print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n","\n","    # Ë©ï‰æ°\n","    model.eval()\n","    y_true, y_pred = [], []\n","    grads_list, inputs_list = [], []\n","\n","    for xb, yb in test_loader:\n","        xb = xb.to(device)\n","        xb.requires_grad = True\n","        preds = model(xb)\n","        preds.sum().backward()\n","\n","        y_true.extend(yb.numpy().flatten())\n","        y_pred.extend(preds.detach().cpu().numpy().flatten())\n","        grads_list.append(xb.grad.detach().cpu().numpy())\n","        inputs_list.append(xb.detach().cpu().numpy())\n","\n","    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n","    r2 = r2_score(y_true, y_pred)\n","    print(f\"‚úÖ {round_name} - RMSE: {rmse:.3f}, R¬≤: {r2:.3f}\")\n","\n","    # ÁµêÊûú‰øùÂ≠ò\n","    pd.DataFrame({'Observed': y_true, 'Predicted': y_pred}).to_csv(\n","        os.path.join(data_path, \"predictions_vit.csv\"), index=False)\n","\n","    # ÈáçË¶ÅÂ∫¶Ë©ï‰æ°ÔºàInput √ó GradientÔºâ\n","    grads = np.concatenate(grads_list, axis=0).squeeze(1)\n","    inputs = np.concatenate(inputs_list, axis=0).squeeze(1)\n","    importance = (inputs * grads).mean(axis=0)  # (91,)\n","\n","    pd.DataFrame({\n","        'Wavelength': spectral_cols,\n","        'Importance': importance\n","    }).to_csv(os.path.join(data_path, \"importance_vit.csv\"), index=False)\n"],"metadata":{"id":"oCtOPojWdNEW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c826e629-651c-44e8-de03-aca4a880d322"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìÅ Round01 Âá¶ÁêÜ‰∏≠...\n","Epoch 10, Loss: 132.0614\n","Epoch 20, Loss: 48.5916\n","Epoch 30, Loss: 26.4947\n","Epoch 40, Loss: 22.9657\n","Epoch 50, Loss: 18.2114\n","Epoch 60, Loss: 13.9599\n","Epoch 70, Loss: 13.1346\n","Epoch 80, Loss: 13.2364\n","Epoch 90, Loss: 12.6906\n","Epoch 100, Loss: 12.9629\n","‚úÖ Round01 - RMSE: 3.615, R¬≤: 0.890\n","\n","üìÅ Round02 Âá¶ÁêÜ‰∏≠...\n","Epoch 10, Loss: 131.5358\n","Epoch 20, Loss: 49.7634\n","Epoch 30, Loss: 30.7927\n","Epoch 40, Loss: 34.8227\n","Epoch 50, Loss: 20.0939\n","Epoch 60, Loss: 17.7418\n","Epoch 70, Loss: 16.4571\n","Epoch 80, Loss: 14.4232\n","Epoch 90, Loss: 26.9344\n"]}]}]}